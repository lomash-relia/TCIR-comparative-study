{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Part 1: Data Preparation and Dataset Class\n",
    "# ======================================\n",
    "\n",
    "# ======================================\n",
    "# Import Necessary Libraries\n",
    "# ======================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from torchvision import models\n",
    "\n",
    "# Install necessary packages if not already installed\n",
    "try:\n",
    "    from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "except ImportError:\n",
    "    !pip install fvcore -q\n",
    "    from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ======================================\n",
    "# Reproducibility\n",
    "# ======================================\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "set_seed(42)\n",
    "\n",
    "# ======================================\n",
    "# Device Configuration\n",
    "# ======================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ======================================\n",
    "# Data Preparation\n",
    "# ======================================\n",
    "# File path to the dataset\n",
    "data_path = '/kaggle/input/tcir-cpac-io-sh-h5-file/TCIR-CPAC_IO_SH.h5'\n",
    "\n",
    "# Load Dataset Information and Filter\n",
    "try:\n",
    "    data_info = pd.read_hdf(data_path, key=\"info\", mode='r')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading HDF5 file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Filter for the 'SH' dataset\n",
    "data_info_filtered = data_info[data_info['data_set'].isin(['SH'])]\n",
    "\n",
    "# Undersampling for Balanced Dataset\n",
    "low_vmax_threshold = np.percentile(data_info_filtered['Vmax'].values, 35)\n",
    "low_vmax_indices = data_info_filtered[\n",
    "    data_info_filtered['Vmax'] <= low_vmax_threshold].index\n",
    "remaining_indices = data_info_filtered[\n",
    "    data_info_filtered['Vmax'] > low_vmax_threshold].index\n",
    "undersample_ratio = 0.3\n",
    "undersample_size = int(len(low_vmax_indices) * undersample_ratio) \\\n",
    "    if len(low_vmax_indices) > 0 else 0\n",
    "\n",
    "if undersample_size > 0:\n",
    "    undersample_indices = np.random.choice(\n",
    "        low_vmax_indices, undersample_size, replace=False)\n",
    "    balanced_indices = np.concatenate(\n",
    "        (undersample_indices, remaining_indices))\n",
    "else:\n",
    "    balanced_indices = remaining_indices\n",
    "\n",
    "data_info_balanced = data_info_filtered.loc[\n",
    "    balanced_indices].reset_index()\n",
    "\n",
    "# Define Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(degrees=(0, 360), fill=0),\n",
    "    transforms.CenterCrop(size=(152, 152)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(size=(152, 152)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Dataset Class\n",
    "class TCIRLazyDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, data_info, channels=[0, 1, 3],\n",
    "                 transform=None):\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.data_info = data_info\n",
    "        self.channels = channels\n",
    "        self.transform = transform\n",
    "        self.channel_norm_values = {0: 350, 1: 275, 3: 4.35}\n",
    "        try:\n",
    "            self.hf = h5py.File(self.hdf5_file, 'r')\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening HDF5 file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            hdf5_index = self.data_info.at[idx, 'index']\n",
    "            data_matrix = self.hf['matrix'][hdf5_index, :, :, self.channels]\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing data at index {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Normalize image data\n",
    "        image = np.empty_like(data_matrix, dtype=np.float32)\n",
    "        for i, ch in enumerate(self.channels):\n",
    "            norm_value = self.channel_norm_values.get(ch, 1.0)\n",
    "            channel_data = data_matrix[:, :, i]\n",
    "            channel_data = np.clip(channel_data, None, norm_value)\n",
    "            image[:, :, i] = np.nan_to_num(channel_data / norm_value)\n",
    "\n",
    "        # Convert to tensor and apply transformations\n",
    "        image = torch.tensor(image).permute(2, 0, 1)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Retrieve the label (Vmax)\n",
    "        label = torch.tensor(\n",
    "            self.data_info.at[idx, 'Vmax'], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'hf') and self.hf:\n",
    "            self.hf.close()\n",
    "\n",
    "# Split Dataset\n",
    "full_dataset_size = len(data_info_balanced)\n",
    "indices = list(range(full_dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_size = int(0.7 * full_dataset_size)\n",
    "val_size = int(0.15 * full_dataset_size)\n",
    "test_size = full_dataset_size - train_size - val_size\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "train_data_info = data_info_balanced.iloc[\n",
    "    train_indices].reset_index(drop=True)\n",
    "val_data_info = data_info_balanced.iloc[\n",
    "    val_indices].reset_index(drop=True)\n",
    "test_data_info = data_info_balanced.iloc[\n",
    "    test_indices].reset_index(drop=True)\n",
    "\n",
    "# Create Dataset Instances\n",
    "train_dataset = TCIRLazyDataset(\n",
    "    data_path, train_data_info, transform=train_transform)\n",
    "val_dataset = TCIRLazyDataset(\n",
    "    data_path, val_data_info, transform=val_test_transform)\n",
    "test_dataset = TCIRLazyDataset(\n",
    "    data_path, test_data_info, transform=val_test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True,\n",
    "    num_workers=3, pin_memory=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=3, pin_memory=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False,\n",
    "    num_workers=3, pin_memory=True)\n",
    "\n",
    "print(f'Total Samples - Train: {len(train_dataset)}, '\n",
    "      f'Validation: {len(val_dataset)}, Test: {len(test_dataset)}')\n",
    "\n",
    "# ======================================\n",
    "# Part 2: Model Definitions (Including CBAM)\n",
    "# ======================================\n",
    "\n",
    "# ======================================\n",
    "# CBAM Attention Module\n",
    "# ======================================\n",
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out).view(b, c, 1, 1)\n",
    "\n",
    "# Spatial Attention Module\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            2, 1, kernel_size, padding=kernel_size // 2,\n",
    "            bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        x_conv = self.conv(x_cat)\n",
    "        return self.sigmoid(x_conv)\n",
    "\n",
    "# CBAM Module\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=8, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(\n",
    "            in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = x * self.channel_attention(x)\n",
    "        x_out = x_out * self.spatial_attention(x_out)\n",
    "        return x_out\n",
    "\n",
    "# ======================================\n",
    "# Function to Create Models Dynamically\n",
    "# ======================================\n",
    "def create_model(architecture, num_channels=3, use_cbam=False):\n",
    "    \"\"\"\n",
    "    Creates a model based on the specified architecture and\n",
    "    whether to use CBAM.\n",
    "\n",
    "    Args:\n",
    "        architecture (str): Name of the architecture ('resnet18', 'resnet34',\n",
    "                            'resnet50', 'densenet121', 'densenet169', 'densenet201').\n",
    "        num_channels (int): Number of input channels.\n",
    "        use_cbam (bool): Whether to include CBAM modules.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Module): The constructed model.\n",
    "    \"\"\"\n",
    "    # Define a mapping from architecture to weights enum\n",
    "    weights_dict = {\n",
    "        'resnet18': models.ResNet18_Weights.DEFAULT,\n",
    "        'resnet34': models.ResNet34_Weights.DEFAULT,\n",
    "        'resnet50': models.ResNet50_Weights.DEFAULT,\n",
    "        'densenet121': models.DenseNet121_Weights.DEFAULT,\n",
    "        'densenet169': models.DenseNet169_Weights.DEFAULT,\n",
    "        'densenet201': models.DenseNet201_Weights.DEFAULT\n",
    "    }\n",
    "    \n",
    "    if architecture not in weights_dict:\n",
    "        raise ValueError(f\"Architecture {architecture} not supported.\")\n",
    "    \n",
    "    weights = weights_dict[architecture]\n",
    "    \n",
    "    if 'resnet' in architecture:\n",
    "        # Load the base model with pretrained weights\n",
    "        base_model = getattr(models, architecture)(weights=weights)\n",
    "        # Modify the first conv layer\n",
    "        base_model.conv1 = nn.Conv2d(\n",
    "            num_channels, 64, kernel_size=7, stride=2,\n",
    "            padding=3, bias=False)\n",
    "        # Modify the fully connected layer\n",
    "        base_model.fc = nn.Sequential(\n",
    "            nn.Linear(base_model.fc.in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        if use_cbam:\n",
    "            # Insert CBAM modules after each residual layer\n",
    "            model = ResNet_CBAM_Modified(base_model)\n",
    "        else:\n",
    "            model = base_model\n",
    "\n",
    "    elif 'densenet' in architecture:\n",
    "        # Load the base model with pretrained weights\n",
    "        base_model = getattr(models, architecture)(weights=weights)\n",
    "        # Modify the first conv layer\n",
    "        base_model.features.conv0 = nn.Conv2d(\n",
    "            num_channels, base_model.features.conv0.out_channels,\n",
    "            kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Modify the classifier\n",
    "        base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(base_model.classifier.in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        if use_cbam:\n",
    "            # Manually set the parameters based on the architecture\n",
    "            if architecture == 'densenet121':\n",
    "                growth_rate = 32\n",
    "                block_config = (6, 12, 24, 16)\n",
    "                compression = 0.5\n",
    "            elif architecture == 'densenet169':\n",
    "                growth_rate = 32\n",
    "                block_config = (6, 12, 32, 32)\n",
    "                compression = 0.5\n",
    "            elif architecture == 'densenet201':\n",
    "                growth_rate = 32\n",
    "                block_config = (6, 12, 48, 32)\n",
    "                compression = 0.5\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown architecture {architecture}\")\n",
    "\n",
    "            # Insert CBAM modules after each dense block\n",
    "            model = DenseNet_CBAM_Modified(\n",
    "                base_model, growth_rate, block_config, compression)\n",
    "        else:\n",
    "            model = base_model\n",
    "    else:\n",
    "        raise ValueError(f\"Architecture {architecture} not supported.\")\n",
    "    return model\n",
    "\n",
    "# ======================================\n",
    "# Modified ResNet and DenseNet Classes with CBAM\n",
    "# ======================================\n",
    "class ResNet_CBAM_Modified(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(ResNet_CBAM_Modified, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        # Determine the expansion factor\n",
    "        if isinstance(self.base_model.layer1[0], models.resnet.BasicBlock):\n",
    "            expansion = 1\n",
    "        elif isinstance(self.base_model.layer1[0], models.resnet.Bottleneck):\n",
    "            expansion = self.base_model.layer1[0].expansion  # This will be 4\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown block type')\n",
    "\n",
    "        # Define CBAM modules with correct in_channels\n",
    "        self.cbam1 = CBAM(64 * expansion)\n",
    "        self.cbam2 = CBAM(128 * expansion)\n",
    "        self.cbam3 = CBAM(256 * expansion)\n",
    "        self.cbam4 = CBAM(512 * expansion)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.conv1(x)\n",
    "        x = self.base_model.bn1(x)\n",
    "        x = self.base_model.relu(x)\n",
    "        x = self.base_model.maxpool(x)\n",
    "\n",
    "        x = self.base_model.layer1(x)\n",
    "        x = self.cbam1(x)\n",
    "\n",
    "        x = self.base_model.layer2(x)\n",
    "        x = self.cbam2(x)\n",
    "\n",
    "        x = self.base_model.layer3(x)\n",
    "        x = self.cbam3(x)\n",
    "\n",
    "        x = self.base_model.layer4(x)\n",
    "        x = self.cbam4(x)\n",
    "\n",
    "        x = self.base_model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.base_model.fc(x)\n",
    "        return x\n",
    "\n",
    "class DenseNet_CBAM_Modified(nn.Module):\n",
    "    def __init__(self, base_model, growth_rate, block_config, compression):\n",
    "        super(DenseNet_CBAM_Modified, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        # Retrieve initial parameters\n",
    "        num_init_features = base_model.features.conv0.out_channels  # Typically 64\n",
    "\n",
    "        # Compute number of features after each dense block\n",
    "        num_features = num_init_features  # Start with num_init_features (64)\n",
    "\n",
    "        # After DenseBlock1\n",
    "        num_features1 = num_features + block_config[0] * growth_rate\n",
    "        num_features = int(num_features1 * compression)\n",
    "\n",
    "        # After DenseBlock2\n",
    "        num_features2 = num_features + block_config[1] * growth_rate\n",
    "        num_features = int(num_features2 * compression)\n",
    "\n",
    "        # After DenseBlock3\n",
    "        num_features3 = num_features + block_config[2] * growth_rate\n",
    "        num_features = int(num_features3 * compression)\n",
    "\n",
    "        # After DenseBlock4\n",
    "        num_features4 = num_features + block_config[3] * growth_rate\n",
    "        # No compression after the last block\n",
    "\n",
    "        # Initialize CBAM modules with correct in_channels\n",
    "        self.cbam1 = CBAM(num_features1)\n",
    "        self.cbam2 = CBAM(num_features2)\n",
    "        self.cbam3 = CBAM(num_features3)\n",
    "        self.cbam4 = CBAM(num_features4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model.features.conv0(x)\n",
    "        features = self.base_model.features.norm0(features)\n",
    "        features = self.base_model.features.relu0(features)\n",
    "        features = self.base_model.features.pool0(features)\n",
    "\n",
    "        # DenseBlock1 + CBAM1\n",
    "        features = self.base_model.features.denseblock1(features)\n",
    "        features = self.cbam1(features)\n",
    "        features = self.base_model.features.transition1(features)\n",
    "\n",
    "        # DenseBlock2 + CBAM2\n",
    "        features = self.base_model.features.denseblock2(features)\n",
    "        features = self.cbam2(features)\n",
    "        features = self.base_model.features.transition2(features)\n",
    "\n",
    "        # DenseBlock3 + CBAM3\n",
    "        features = self.base_model.features.denseblock3(features)\n",
    "        features = self.cbam3(features)\n",
    "        features = self.base_model.features.transition3(features)\n",
    "\n",
    "        # DenseBlock4 + CBAM4\n",
    "        features = self.base_model.features.denseblock4(features)\n",
    "        features = self.cbam4(features)\n",
    "\n",
    "        features = self.base_model.features.norm5(features)\n",
    "        features = nn.functional.relu(features, inplace=True)\n",
    "        out = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.base_model.classifier(out)\n",
    "        return out\n",
    "\n",
    "# ======================================\n",
    "# Part 3: Training, Evaluation, and Results Compilation\n",
    "# ======================================\n",
    "\n",
    "# ======================================\n",
    "# Training and Evaluation Functions\n",
    "# ======================================\n",
    "def train_and_evaluate(model, train_loader, val_loader,\n",
    "                       num_epochs=100, patience=15,\n",
    "                       checkpoint_path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Trains the model and evaluates it on the validation set.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        num_epochs (int): Maximum number of epochs.\n",
    "        patience (int): Early stopping patience.\n",
    "        checkpoint_path (str): Path to save the best model.\n",
    "\n",
    "    Returns:\n",
    "        train_losses (list): List of training losses per epoch.\n",
    "        val_losses (list): List of validation losses per epoch.\n",
    "        model (nn.Module): The best trained model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.3f}, \"\n",
    "              f\"Val Loss: {val_loss:.3f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "    return train_losses, val_losses, model\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        test_loader (DataLoader): DataLoader for test data.\n",
    "\n",
    "    Returns:\n",
    "        mae (float): Mean Absolute Error.\n",
    "        rmse (float): Root Mean Squared Error.\n",
    "        r2 (float): RÂ² Score.\n",
    "        predictions (np.array): Model predictions.\n",
    "        actuals (np.array): Actual labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).squeeze(1).cpu().numpy()\n",
    "            labels = labels.numpy()\n",
    "            predictions.extend(outputs)\n",
    "            actuals.extend(labels)\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    return mae, rmse, r2, predictions, actuals\n",
    "\n",
    "def get_model_complexity(model, input_size=(3, 224, 224)):\n",
    "    \"\"\"\n",
    "    Computes the total number of parameters and FLOPs of the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to analyze.\n",
    "        input_size (tuple): Size of the input tensor.\n",
    "\n",
    "    Returns:\n",
    "        total_params (int): Total number of parameters.\n",
    "        total_flops (int): Total number of floating-point operations.\n",
    "    \"\"\"\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, *input_size)\n",
    "    try:\n",
    "        flop_count = FlopCountAnalysis(model, dummy_input)\n",
    "        total_flops = flop_count.total()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating FLOPs: {e}\")\n",
    "        total_flops = None\n",
    "\n",
    "    # Calculate total parameters\n",
    "    total_params = parameter_count(model)['']\n",
    "    return total_params, total_flops\n",
    "\n",
    "# ======================================\n",
    "# Model Architectures to Train\n",
    "# ======================================\n",
    "architectures = [\n",
    "    'resnet18',\n",
    "    'resnet34',\n",
    "    'resnet50',\n",
    "    'densenet121',\n",
    "    'densenet169',\n",
    "    'densenet201'\n",
    "]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over architectures and CBAM option\n",
    "for architecture in architectures:\n",
    "    for use_cbam in [True, False]:\n",
    "        model_name = f\"{architecture.upper()} \" \\\n",
    "                     f\"{'with CBAM' if use_cbam else 'without CBAM'}\"\n",
    "        print(f\"\\nTraining {model_name}...\\n\")\n",
    "\n",
    "        # Create the model\n",
    "        try:\n",
    "            model = create_model(\n",
    "                architecture, num_channels=3, use_cbam=use_cbam)\n",
    "        except ValueError as ve:\n",
    "            print(f\"Error creating model {model_name}: {ve}\")\n",
    "            continue\n",
    "\n",
    "        # Define checkpoint path\n",
    "        checkpoint_path = f\"best_model_{architecture}\" \\\n",
    "                          f\"{'_cbam' if use_cbam else ''}.pth\"\n",
    "\n",
    "        # Train the model\n",
    "        train_losses, val_losses, best_model = train_and_evaluate(\n",
    "            model, train_loader, val_loader,\n",
    "            num_epochs=100, patience=15,\n",
    "            checkpoint_path=checkpoint_path)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        print(f\"\\nEvaluating {model_name} on test set...\\n\")\n",
    "        mae, rmse, r2, predictions, actuals = evaluate_model(\n",
    "            best_model, test_loader)\n",
    "        print(f\"{model_name} - Test MAE: {mae:.3f}, \"\n",
    "              f\"RMSE: {rmse:.3f}, R2 Score: {r2:.3f}\")\n",
    "\n",
    "        # Compute FLOPs and Params\n",
    "        print(f\"\\nCalculating FLOPs and Parameters \"\n",
    "              f\"for {model_name}...\\n\")\n",
    "        total_params, total_flops = get_model_complexity(best_model)\n",
    "        if total_flops is not None:\n",
    "            flops_display = f\"{total_flops:,}\"\n",
    "        else:\n",
    "            flops_display = \"N/A\"\n",
    "        print(f\"{model_name} - Total Params: \"\n",
    "              f\"{total_params:,}, Total FLOPs: {flops_display}\")\n",
    "\n",
    "        # Save training history\n",
    "        history_df = pd.DataFrame({\n",
    "            'Epoch': range(1, len(train_losses) + 1),\n",
    "            'Train Loss': train_losses,\n",
    "            'Val Loss': val_losses\n",
    "        })\n",
    "        history_csv_path = f\"training_history_{architecture}\" \\\n",
    "                           f\"{'_cbam' if use_cbam else ''}.csv\"\n",
    "        history_df.to_csv(history_csv_path, index=False)\n",
    "        print(f\"\\nTraining history saved to '{history_csv_path}'\")\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2 Score': r2,\n",
    "            'Total Params': total_params,\n",
    "            'Total FLOPs': total_flops\n",
    "        })\n",
    "\n",
    "# ======================================\n",
    "# Compile Results into a Table\n",
    "# ======================================\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('model_evaluation_results.csv', index=False)\n",
    "print(\"\\nModel evaluation results saved to \"\n",
    "      \"'model_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
